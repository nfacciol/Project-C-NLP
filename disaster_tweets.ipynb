{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facciola NLP Disaster Tweet Model\n",
    "\n",
    "- In this competition we are building an NLP model to predict whether a Tweet is about a real disaster or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "DATA_DIR = os.path.join(os.getcwd(),'data') if os.environ['COMPUTERNAME'] == 'NFACCIOL-MOBL' else \"/kaggle/input/nlp-getting-started/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "- examine the structure of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n",
      "None\n",
      "\n",
      "Test set info\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set info\")\n",
    "print(train_df.info())\n",
    "print()\n",
    "print(\"Test set info\")\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "- here we clean the text data by removing unneccssary characters, handling missing values, and normalizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nfacciol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason #earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive #wildfires evacuation ord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby #alaska smoke #wildfires p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         clean_text  \n",
       "0       1      deeds reason #earthquake may allah forgive us  \n",
       "1       1              forest fire near la ronge sask canada  \n",
       "2       1  residents asked shelter place notified officer...  \n",
       "3       1  13000 people receive #wildfires evacuation ord...  \n",
       "4       1  got sent photo ruby #alaska smoke #wildfires p...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.set_proxy('http://proxy-dmz.intel.com:911/')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "#print(stop_words)\n",
    "\n",
    "def clean_text(text):\n",
    "   #remove URLS\n",
    "   text = re.sub(r'http\\S+', '', text)\n",
    "   #remove HTML tags\n",
    "   text = re.sub(r'<.*?>', '', text)\n",
    "   # Remove non-alphanumeric characters except hashtags and mentions\n",
    "   text = re.sub(r'[^a-zA-Z0-9\\s#@]', '', text)\n",
    "   # Convert to lowercase\n",
    "   text = text.lower()\n",
    "   # Remove stopwords\n",
    "   text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "   return text\n",
    "\n",
    "train_df['clean_text'] = train_df['text'].apply(clean_text)\n",
    "test_df['clean_text'] = test_df['text'].apply(clean_text)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- **text length**: Calculate the length of each tweet. This can help capture information about tweet complexity or verbosity.\n",
    "- **word count**: Count the number of words in each tweet, which may provide insight into tweet structure.\n",
    "- **hashtag count**: Count the number of hashtags in each tweet, as this can be indicative of topic relevance or trending discussions.\n",
    "- **mention count**: Count the number of user mentions, which can indicate the tweet's engagement level.\n",
    "- **hasUrl**: Create a binary feature indicating whether the tweet contains a URL.\n",
    "- **sentiment score**: Use a pre-trained sentiment analyzer to get a sentiment score for each tweet.\n",
    "- **pos tags**: Count the occurrence of different parts of speech in each tweet.\n",
    "- **profanity count**: Count the number of profane words in each tweet using a predefined list of profane words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5690</th>\n",
       "      <td>8120</td>\n",
       "      <td>rescued</td>\n",
       "      <td>Winston-Salem, NC</td>\n",
       "      <td>'You can only be rescued from where you actual...</td>\n",
       "      <td>0</td>\n",
       "      <td>rescued actually pretend giorgio hiatt</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078</th>\n",
       "      <td>4415</td>\n",
       "      <td>electrocute</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electric vs Gas brewing (not wanting to electr...</td>\n",
       "      <td>0</td>\n",
       "      <td>electric vs gas brewing wanting electrocute qu...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4835</th>\n",
       "      <td>6882</td>\n",
       "      <td>mass%20murder</td>\n",
       "      <td>New Sweden</td>\n",
       "      <td>The media needs to stop publicizing mass murde...</td>\n",
       "      <td>0</td>\n",
       "      <td>media needs stop publicizing mass murder many ...</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>5140</td>\n",
       "      <td>fatal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>\n",
       "      <td>1</td>\n",
       "      <td>11yearold boy charged manslaughter toddler rep...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>1066</td>\n",
       "      <td>bleeding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@SoDamnTrue  we know who u are you're a bleedi...</td>\n",
       "      <td>0</td>\n",
       "      <td>@sodamntrue know u youre bleeding heart wannab...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        keyword           location  \\\n",
       "5690  8120        rescued  Winston-Salem, NC   \n",
       "3078  4415    electrocute                NaN   \n",
       "4835  6882  mass%20murder         New Sweden   \n",
       "3600  5140          fatal                NaN   \n",
       "736   1066       bleeding                NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "5690  'You can only be rescued from where you actual...       0   \n",
       "3078  Electric vs Gas brewing (not wanting to electr...       0   \n",
       "4835  The media needs to stop publicizing mass murde...       0   \n",
       "3600  11-Year-Old Boy Charged With Manslaughter of T...       1   \n",
       "736   @SoDamnTrue  we know who u are you're a bleedi...       0   \n",
       "\n",
       "                                             clean_text  text_length  \n",
       "5690             rescued actually pretend giorgio hiatt          107  \n",
       "3078  electric vs gas brewing wanting electrocute qu...           91  \n",
       "4835  media needs stop publicizing mass murder many ...          135  \n",
       "3600  11yearold boy charged manslaughter toddler rep...          136  \n",
       "736   @sodamntrue know u youre bleeding heart wannab...           76  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text_length'] = train_df['text'].apply(len)\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>2303</td>\n",
       "      <td>cliff%20fall</td>\n",
       "      <td>The Netherlands</td>\n",
       "      <td>#NowPlaying * Cliff Richard - I Could Easily F...</td>\n",
       "      <td>0</td>\n",
       "      <td>#nowplaying cliff richard could easily fall lo...</td>\n",
       "      <td>137</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6198</th>\n",
       "      <td>8846</td>\n",
       "      <td>smoke</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>smoke whatever you got</td>\n",
       "      <td>0</td>\n",
       "      <td>smoke whatever got</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>4393</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>London</td>\n",
       "      <td>'There was a small earthquake in LA but don't ...</td>\n",
       "      <td>1</td>\n",
       "      <td>small earthquake la dont worry emmy rossum fine</td>\n",
       "      <td>72</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>321</td>\n",
       "      <td>annihilated</td>\n",
       "      <td>the own zone layer</td>\n",
       "      <td>day 1 of tryouts went good minus the fact I st...</td>\n",
       "      <td>0</td>\n",
       "      <td>day 1 tryouts went good minus fact stopped qui...</td>\n",
       "      <td>123</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>6421</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>The Globe</td>\n",
       "      <td>HURRICANE GUILLERMO LIVE NOAA TRACKING / LOOPI...</td>\n",
       "      <td>1</td>\n",
       "      <td>hurricane guillermo live noaa tracking looping...</td>\n",
       "      <td>134</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       keyword             location  \\\n",
       "1595  2303  cliff%20fall      The Netherlands   \n",
       "6198  8846         smoke       Rio de Janeiro   \n",
       "3062  4393    earthquake               London   \n",
       "226    321   annihilated  the own zone layer    \n",
       "4519  6421     hurricane            The Globe   \n",
       "\n",
       "                                                   text  target  \\\n",
       "1595  #NowPlaying * Cliff Richard - I Could Easily F...       0   \n",
       "6198                             smoke whatever you got       0   \n",
       "3062  'There was a small earthquake in LA but don't ...       1   \n",
       "226   day 1 of tryouts went good minus the fact I st...       0   \n",
       "4519  HURRICANE GUILLERMO LIVE NOAA TRACKING / LOOPI...       1   \n",
       "\n",
       "                                             clean_text  text_length  \\\n",
       "1595  #nowplaying cliff richard could easily fall lo...          137   \n",
       "6198                                 smoke whatever got           22   \n",
       "3062    small earthquake la dont worry emmy rossum fine           72   \n",
       "226   day 1 tryouts went good minus fact stopped qui...          123   \n",
       "4519  hurricane guillermo live noaa tracking looping...          134   \n",
       "\n",
       "      word_count  \n",
       "1595          21  \n",
       "6198           4  \n",
       "3062          14  \n",
       "226           24  \n",
       "4519          13  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['word_count'] = train_df['text'].apply(lambda x: len(x.split()))\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>1657</td>\n",
       "      <td>bombing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@snapharmony : Bells toll in Hiroshima as Japa...</td>\n",
       "      <td>1</td>\n",
       "      <td>@snapharmony bells toll hiroshima japan marks ...</td>\n",
       "      <td>106</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>2000</td>\n",
       "      <td>bush%20fires</td>\n",
       "      <td>Sydney, Australia</td>\n",
       "      <td>SMH photographer Wolter Peeters was on the fro...</td>\n",
       "      <td>1</td>\n",
       "      <td>smh photographer wolter peeters front line nsw...</td>\n",
       "      <td>139</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4874</th>\n",
       "      <td>6939</td>\n",
       "      <td>mass%20murderer</td>\n",
       "      <td>Tama, Iowa</td>\n",
       "      <td>Nazi Mass Murderer Became Chairman At Vaccine ...</td>\n",
       "      <td>1</td>\n",
       "      <td>nazi mass murderer became chairman vaccine dru...</td>\n",
       "      <td>87</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>2670</td>\n",
       "      <td>crush</td>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>Had a minute alone with my crush??...it was an...</td>\n",
       "      <td>0</td>\n",
       "      <td>minute alone crushit overrated experiencesmh</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474</th>\n",
       "      <td>4969</td>\n",
       "      <td>explosion</td>\n",
       "      <td>Germany</td>\n",
       "      <td>I liked a @YouTube video http://t.co/bGAJ2oAX1...</td>\n",
       "      <td>1</td>\n",
       "      <td>liked @youtube video huge building explosion 2...</td>\n",
       "      <td>101</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id          keyword           location  \\\n",
       "1150  1657          bombing                NaN   \n",
       "1387  2000     bush%20fires  Sydney, Australia   \n",
       "4874  6939  mass%20murderer         Tama, Iowa   \n",
       "1857  2670            crush             GLOBAL   \n",
       "3474  4969        explosion            Germany   \n",
       "\n",
       "                                                   text  target  \\\n",
       "1150  @snapharmony : Bells toll in Hiroshima as Japa...       1   \n",
       "1387  SMH photographer Wolter Peeters was on the fro...       1   \n",
       "4874  Nazi Mass Murderer Became Chairman At Vaccine ...       1   \n",
       "1857  Had a minute alone with my crush??...it was an...       0   \n",
       "3474  I liked a @YouTube video http://t.co/bGAJ2oAX1...       1   \n",
       "\n",
       "                                             clean_text  text_length  \\\n",
       "1150  @snapharmony bells toll hiroshima japan marks ...          106   \n",
       "1387  smh photographer wolter peeters front line nsw...          139   \n",
       "4874  nazi mass murderer became chairman vaccine dru...           87   \n",
       "1857       minute alone crushit overrated experiencesmh           73   \n",
       "3474  liked @youtube video huge building explosion 2...          101   \n",
       "\n",
       "      word_count  hashtag_count  \n",
       "1150          15              0  \n",
       "1387          18              0  \n",
       "4874          11              0  \n",
       "1857          11              0  \n",
       "3474          16              0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['hashtag_count'] = train_df['text'].apply(lambda x: len([w for w in x.split() if w.startswith('#')]))\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7228</th>\n",
       "      <td>10350</td>\n",
       "      <td>weapons</td>\n",
       "      <td>Incognito</td>\n",
       "      <td>WOOOOOOO RT @GameRant: Call of Duty: Black Ops...</td>\n",
       "      <td>0</td>\n",
       "      <td>wooooooo rt @gamerant call duty black ops 3 es...</td>\n",
       "      <td>132</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3375</th>\n",
       "      <td>4833</td>\n",
       "      <td>evacuation</td>\n",
       "      <td>USA</td>\n",
       "      <td>Bend Post Office roofers cut gas line prompt e...</td>\n",
       "      <td>1</td>\n",
       "      <td>bend post office roofers cut gas line prompt e...</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6452</th>\n",
       "      <td>9231</td>\n",
       "      <td>suicide%20bombing</td>\n",
       "      <td>EARTH</td>\n",
       "      <td>@NBCPolitics RUSSIA AND THAT BACK FIRED NOW 20...</td>\n",
       "      <td>1</td>\n",
       "      <td>@nbcpolitics russia back fired 2015 look happe...</td>\n",
       "      <td>137</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>8886</td>\n",
       "      <td>smoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I miss Josie cause I wanna smoke splifs and go...</td>\n",
       "      <td>0</td>\n",
       "      <td>miss josie cause wanna smoke splifs go taco bell</td>\n",
       "      <td>62</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>7274</td>\n",
       "      <td>nuclear%20disaster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 Former Executives To Be Prosecuted In Fukush...</td>\n",
       "      <td>1</td>\n",
       "      <td>3 former executives prosecuted fukushima nucle...</td>\n",
       "      <td>89</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id             keyword   location  \\\n",
       "7228  10350             weapons  Incognito   \n",
       "3375   4833          evacuation        USA   \n",
       "6452   9231   suicide%20bombing      EARTH   \n",
       "6225   8886               smoke        NaN   \n",
       "5099   7274  nuclear%20disaster        NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "7228  WOOOOOOO RT @GameRant: Call of Duty: Black Ops...       0   \n",
       "3375  Bend Post Office roofers cut gas line prompt e...       1   \n",
       "6452  @NBCPolitics RUSSIA AND THAT BACK FIRED NOW 20...       1   \n",
       "6225  I miss Josie cause I wanna smoke splifs and go...       0   \n",
       "5099  3 Former Executives To Be Prosecuted In Fukush...       1   \n",
       "\n",
       "                                             clean_text  text_length  \\\n",
       "7228  wooooooo rt @gamerant call duty black ops 3 es...          132   \n",
       "3375  bend post office roofers cut gas line prompt e...           80   \n",
       "6452  @nbcpolitics russia back fired 2015 look happe...          137   \n",
       "6225   miss josie cause wanna smoke splifs go taco bell           62   \n",
       "5099  3 former executives prosecuted fukushima nucle...           89   \n",
       "\n",
       "      word_count  hashtag_count  mention_count  \n",
       "7228          17              0              1  \n",
       "3375          11              0              0  \n",
       "6452          21              0              1  \n",
       "6225          14              0              0  \n",
       "5099          11              0              0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['mention_count'] = train_df['text'].apply(lambda x: len([w for w in x.split() if w.startswith('@')]))\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>has_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>9288</td>\n",
       "      <td>sunk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Everything has sunk in except the fact that I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>everything sunk except fact actually moving st...</td>\n",
       "      <td>140</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4665</th>\n",
       "      <td>6631</td>\n",
       "      <td>inundated</td>\n",
       "      <td>Paducah, KY</td>\n",
       "      <td>@Bilsko and suddenly I'm inundated with resear...</td>\n",
       "      <td>1</td>\n",
       "      <td>@bilsko suddenly im inundated research @humoft...</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>4033</td>\n",
       "      <td>disaster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@cncpts @SOLELINKS what a disaster - can't say...</td>\n",
       "      <td>0</td>\n",
       "      <td>@cncpts @solelinks disaster cant say im surprised</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6727</th>\n",
       "      <td>9640</td>\n",
       "      <td>thunderstorm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Falling asleep to the sounds to thousands of R...</td>\n",
       "      <td>0</td>\n",
       "      <td>falling asleep sounds thousands river plate fa...</td>\n",
       "      <td>111</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>3180</td>\n",
       "      <td>deluge</td>\n",
       "      <td>London</td>\n",
       "      <td>Perhaps 'historic' should be applied not to th...</td>\n",
       "      <td>1</td>\n",
       "      <td>perhaps historic applied deluge recently expos...</td>\n",
       "      <td>136</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       keyword     location  \\\n",
       "6496  9288          sunk          NaN   \n",
       "4665  6631     inundated  Paducah, KY   \n",
       "2805  4033      disaster          NaN   \n",
       "6727  9640  thunderstorm          NaN   \n",
       "2222  3180        deluge       London   \n",
       "\n",
       "                                                   text  target  \\\n",
       "6496  Everything has sunk in except the fact that I ...       0   \n",
       "4665  @Bilsko and suddenly I'm inundated with resear...       1   \n",
       "2805  @cncpts @SOLELINKS what a disaster - can't say...       0   \n",
       "6727  Falling asleep to the sounds to thousands of R...       0   \n",
       "2222  Perhaps 'historic' should be applied not to th...       1   \n",
       "\n",
       "                                             clean_text  text_length  \\\n",
       "6496  everything sunk except fact actually moving st...          140   \n",
       "4665  @bilsko suddenly im inundated research @humoft...           63   \n",
       "2805  @cncpts @solelinks disaster cant say im surprised           60   \n",
       "6727  falling asleep sounds thousands river plate fa...          111   \n",
       "2222  perhaps historic applied deluge recently expos...          136   \n",
       "\n",
       "      word_count  hashtag_count  mention_count  has_url  \n",
       "6496          27              0              0        0  \n",
       "4665           8              0              2        0  \n",
       "2805          10              0              2        0  \n",
       "6727          18              1              0        0  \n",
       "2222          21              1              0        0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['has_url'] = train_df['text'].apply(lambda x: 1 if re.search(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", x) else 0)\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>has_url</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>10314</td>\n",
       "      <td>weapon</td>\n",
       "      <td>California, United States</td>\n",
       "      <td>#InsaneLimits #plugin enabled  @'    =TPS= | T...</td>\n",
       "      <td>0</td>\n",
       "      <td>#insanelimits #plugin enabled @ tps tdm 400t h...</td>\n",
       "      <td>106</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>299</td>\n",
       "      <td>annihilated</td>\n",
       "      <td>Boksburg</td>\n",
       "      <td>@marksmaponyane Hey!Sundowns were annihilated ...</td>\n",
       "      <td>0</td>\n",
       "      <td>@marksmaponyane heysundowns annihilated previo...</td>\n",
       "      <td>110</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>5468</td>\n",
       "      <td>flames</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>'if you can't summon the flames directly from ...</td>\n",
       "      <td>0</td>\n",
       "      <td>cant summon flames directly hell store bought ...</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.258333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3375</th>\n",
       "      <td>4833</td>\n",
       "      <td>evacuation</td>\n",
       "      <td>USA</td>\n",
       "      <td>Bend Post Office roofers cut gas line prompt e...</td>\n",
       "      <td>1</td>\n",
       "      <td>bend post office roofers cut gas line prompt e...</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6632</th>\n",
       "      <td>9499</td>\n",
       "      <td>terrorist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HereÛªs how media in Pakistan covered the cap...</td>\n",
       "      <td>1</td>\n",
       "      <td>heres media pakistan covered capture terrorist...</td>\n",
       "      <td>101</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id      keyword                   location  \\\n",
       "7199  10314       weapon  California, United States   \n",
       "212     299  annihilated                   Boksburg   \n",
       "3843   5468       flames              Manhattan, NY   \n",
       "3375   4833   evacuation                        USA   \n",
       "6632   9499    terrorist                        NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "7199  #InsaneLimits #plugin enabled  @'    =TPS= | T...       0   \n",
       "212   @marksmaponyane Hey!Sundowns were annihilated ...       0   \n",
       "3843  'if you can't summon the flames directly from ...       0   \n",
       "3375  Bend Post Office roofers cut gas line prompt e...       1   \n",
       "6632  HereÛªs how media in Pakistan covered the cap...       1   \n",
       "\n",
       "                                             clean_text  text_length  \\\n",
       "7199  #insanelimits #plugin enabled @ tps tdm 400t h...          106   \n",
       "212   @marksmaponyane heysundowns annihilated previo...          110   \n",
       "3843  cant summon flames directly hell store bought ...           87   \n",
       "3375  bend post office roofers cut gas line prompt e...           80   \n",
       "6632  heres media pakistan covered capture terrorist...          101   \n",
       "\n",
       "      word_count  hashtag_count  mention_count  has_url  sentiment_score  \n",
       "7199          19              2              1        0         0.000000  \n",
       "212           13              0              1        0        -0.166667  \n",
       "3843          14              0              0        0         0.258333  \n",
       "3375          11              0              0        1         0.000000  \n",
       "6632          13              0              0        1         0.000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "train_df['sentiment_score'] = train_df['text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>has_url</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>adjective_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>1215</td>\n",
       "      <td>blizzard</td>\n",
       "      <td>United States</td>\n",
       "      <td>@LoneWolffur control yourself tora</td>\n",
       "      <td>0</td>\n",
       "      <td>@lonewolffur control tora</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3378</th>\n",
       "      <td>4836</td>\n",
       "      <td>evacuation</td>\n",
       "      <td>UK</td>\n",
       "      <td>FAAN gives owners of abandoned aircraft evacua...</td>\n",
       "      <td>1</td>\n",
       "      <td>faan gives owners abandoned aircraft evacuatio...</td>\n",
       "      <td>131</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>613</td>\n",
       "      <td>arsonist</td>\n",
       "      <td>NYC :) Ex- #Islamophobe</td>\n",
       "      <td>#Vegetarian #Vegan Video shows arsonist torchi...</td>\n",
       "      <td>0</td>\n",
       "      <td>#vegetarian #vegan video shows arsonist torchi...</td>\n",
       "      <td>136</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>4765</td>\n",
       "      <td>evacuated</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Green line service on south side disrupted aft...</td>\n",
       "      <td>1</td>\n",
       "      <td>green line service south side disrupted cta tr...</td>\n",
       "      <td>134</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>501</td>\n",
       "      <td>army</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.Beyonce Is my pick for http://t.co/thoYhrHk...</td>\n",
       "      <td>0</td>\n",
       "      <td>22beyonce pick fan army #beyhive</td>\n",
       "      <td>89</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     keyword                 location  \\\n",
       "837   1215    blizzard            United States   \n",
       "3378  4836  evacuation                       UK   \n",
       "423    613    arsonist  NYC :) Ex- #Islamophobe   \n",
       "3326  4765   evacuated              Chicago, IL   \n",
       "349    501        army                      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "837                  @LoneWolffur control yourself tora       0   \n",
       "3378  FAAN gives owners of abandoned aircraft evacua...       1   \n",
       "423   #Vegetarian #Vegan Video shows arsonist torchi...       0   \n",
       "3326  Green line service on south side disrupted aft...       1   \n",
       "349   22.Beyonce Is my pick for http://t.co/thoYhrHk...       0   \n",
       "\n",
       "                                             clean_text  text_length  \\\n",
       "837                           @lonewolffur control tora           34   \n",
       "3378  faan gives owners abandoned aircraft evacuatio...          131   \n",
       "423   #vegetarian #vegan video shows arsonist torchi...          136   \n",
       "3326  green line service south side disrupted cta tr...          134   \n",
       "349                    22beyonce pick fan army #beyhive           89   \n",
       "\n",
       "      word_count  hashtag_count  mention_count  has_url  sentiment_score  \\\n",
       "837            4              0              1        0              0.0   \n",
       "3378          16              0              1        1              0.0   \n",
       "423           14              4              0        1              0.6   \n",
       "3326          15              0              0        1             -0.2   \n",
       "349           10              1              0        1              0.0   \n",
       "\n",
       "      noun_count  verb_count  adverb_count  adjective_count  \n",
       "837            2           1             0                0  \n",
       "3378           6           4             1                0  \n",
       "423            9           3             3                1  \n",
       "3326           9           3             0                2  \n",
       "349            7           0             0                0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "train_df['noun_count'] = train_df['text'].apply(lambda x: len([token.pos_ for token in nlp(x) if token.pos_ == 'NOUN' or token.pos_ == 'PROPN']))\n",
    "train_df['verb_count'] = train_df['text'].apply(lambda x: len([token.pos_ for token in nlp(x) if token.pos_ == 'VERB']))\n",
    "train_df['adverb_count'] = train_df['text'].apply(lambda x: len([token.pos_ for token in nlp(x) if token.pos_ == 'ADV']))\n",
    "train_df['adjective_count'] = train_df['text'].apply(lambda x: len([token.pos_ for token in nlp(x) if token.pos_ == 'ADJ']))\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>has_url</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>profanity_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>4785</td>\n",
       "      <td>evacuated</td>\n",
       "      <td>Queensland, Australia</td>\n",
       "      <td>Passengers evacuated &amp;amp; lanes blocked off a...</td>\n",
       "      <td>1</td>\n",
       "      <td>passengers evacuated amp lanes blocked power l...</td>\n",
       "      <td>131</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.155556</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>3914</td>\n",
       "      <td>devastated</td>\n",
       "      <td>London</td>\n",
       "      <td>ÛÏRichmond Coaches were devastated to hear of...</td>\n",
       "      <td>1</td>\n",
       "      <td>richmond coaches devastated hear death second ...</td>\n",
       "      <td>139</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>5894</td>\n",
       "      <td>harm</td>\n",
       "      <td>where the wild things are</td>\n",
       "      <td>I concur. The longer you spend with your child...</td>\n",
       "      <td>0</td>\n",
       "      <td>concur longer spend child harm mmk</td>\n",
       "      <td>90</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4942</th>\n",
       "      <td>7044</td>\n",
       "      <td>mayhem</td>\n",
       "      <td>107-18 79TH STREET</td>\n",
       "      <td>#NoSurrender Results: Full Metal Mayhem World ...</td>\n",
       "      <td>0</td>\n",
       "      <td>#nosurrender results full metal mayhem world t...</td>\n",
       "      <td>135</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889</th>\n",
       "      <td>8410</td>\n",
       "      <td>sandstorm</td>\n",
       "      <td>USA</td>\n",
       "      <td>Watch This Airport Get Swallowed Up By A Sands...</td>\n",
       "      <td>1</td>\n",
       "      <td>watch airport get swallowed sandstorm minute</td>\n",
       "      <td>91</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     keyword                   location  \\\n",
       "3341  4785   evacuated      Queensland, Australia   \n",
       "2725  3914  devastated                     London   \n",
       "4147  5894        harm  where the wild things are   \n",
       "4942  7044      mayhem         107-18 79TH STREET   \n",
       "5889  8410   sandstorm                        USA   \n",
       "\n",
       "                                                   text  target  \\\n",
       "3341  Passengers evacuated &amp; lanes blocked off a...       1   \n",
       "2725  ÛÏRichmond Coaches were devastated to hear of...       1   \n",
       "4147  I concur. The longer you spend with your child...       0   \n",
       "4942  #NoSurrender Results: Full Metal Mayhem World ...       0   \n",
       "5889  Watch This Airport Get Swallowed Up By A Sands...       1   \n",
       "\n",
       "                                             clean_text  text_length  \\\n",
       "3341  passengers evacuated amp lanes blocked power l...          131   \n",
       "2725  richmond coaches devastated hear death second ...          139   \n",
       "4147                 concur longer spend child harm mmk           90   \n",
       "4942  #nosurrender results full metal mayhem world t...          135   \n",
       "5889       watch airport get swallowed sandstorm minute           91   \n",
       "\n",
       "      word_count  hashtag_count  mention_count  has_url  sentiment_score  \\\n",
       "3341          18              0              1        1        -0.155556   \n",
       "2725          20              0              0        1         0.000000   \n",
       "4147          14              0              0        1         0.500000   \n",
       "4942          21              1              0        1         0.487500   \n",
       "5889          14              0              0        1         0.000000   \n",
       "\n",
       "      noun_count  verb_count  adverb_count  adjective_count  profanity_count  \n",
       "3341           8           3             0                0                0  \n",
       "2725           9           2             0                1                0  \n",
       "4147           3           3             1                1                0  \n",
       "4942          12           2             0                2                0  \n",
       "5889           5           2             0                0                0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from better_profanity import profanity\n",
    "\n",
    "train_df['profanity_count'] = train_df['text'].apply(lambda x: len([w for w in x if w in profanity.CENSOR_WORDSET]))\n",
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set Feature engineering\n",
    "- now apply the same to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['text_length'] = test_df['text'].apply(len)\n",
    "test_df['word_count'] = test_df['text'].apply(lambda x: len(x.split()))\n",
    "test_df['hashtag_count'] = test_df['text'].apply(lambda x: len([w for w in x.split() if w.startswith('#')]))\n",
    "test_df['mention_count'] = test_df['text'].apply(lambda x: len([w for w in x.split() if w.startswith('@')]))\n",
    "test_df['has_url'] = test_df['text'].apply(lambda x: 1 if re.search(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", x) else 0)\n",
    "test_df['sentiment_score'] = test_df['text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "test_df['noun_count'] = test_df['text'].apply(lambda x: len([token.pos_ for token in nlp(x) if token.pos_ == 'NOUN' or token.pos_ == 'PROPN']))\n",
    "test_df['verb_count'] = test_df['text'].apply(lambda x: len([token.pos_ for token in nlp(x) if token.pos_ == 'VERB']))\n",
    "test_df['adverb_count'] = test_df['text'].apply(lambda x: len([token.pos_ for token in nlp(x) if token.pos_ == 'ADV']))\n",
    "test_df['adjective_count'] = test_df['text'].apply(lambda x: len([token.pos_ for token in nlp(x) if token.pos_ == 'ADJ']))\n",
    "test_df['profanity_count'] = test_df['text'].apply(lambda x: len([w for w in x if w in profanity.CENSOR_WORDSET]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>has_url</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adverb_count</th>\n",
       "      <th>adjective_count</th>\n",
       "      <th>profanity_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>3384</td>\n",
       "      <td>demolition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Johnny_Detroit Tag Team for me was Demolition...</td>\n",
       "      <td>@johnnydetroit tag team demolition awesome int...</td>\n",
       "      <td>117</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>3224</td>\n",
       "      <td>deluged</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Businesses a e deluged with invoices. Make you...</td>\n",
       "      <td>businesses e deluged invoices make standwout c...</td>\n",
       "      <td>132</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>2066</td>\n",
       "      <td>casualty</td>\n",
       "      <td>among the socially awkward ?</td>\n",
       "      <td>@5SOSFamUpdater social casualty</td>\n",
       "      <td>@5sosfamupdater social casualty</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>416</td>\n",
       "      <td>apocalypse</td>\n",
       "      <td>ColoRADo</td>\n",
       "      <td>@TMFK_CO sounds like a terrible time. I'll be ...</td>\n",
       "      <td>@tmfkco sounds like terrible time ill right</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.357143</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>8879</td>\n",
       "      <td>smoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[55432] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
       "      <td>55432 1950 lionel trains smoke locomotives mag...</td>\n",
       "      <td>123</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     keyword                      location  \\\n",
       "1032  3384  demolition                           NaN   \n",
       "972   3224     deluged                           NaN   \n",
       "634   2066    casualty  among the socially awkward ?   \n",
       "131    416  apocalypse                      ColoRADo   \n",
       "2658  8879       smoke                           NaN   \n",
       "\n",
       "                                                   text  \\\n",
       "1032  @Johnny_Detroit Tag Team for me was Demolition...   \n",
       "972   Businesses a e deluged with invoices. Make you...   \n",
       "634                     @5SOSFamUpdater social casualty   \n",
       "131   @TMFK_CO sounds like a terrible time. I'll be ...   \n",
       "2658  [55432] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...   \n",
       "\n",
       "                                             clean_text  text_length  \\\n",
       "1032  @johnnydetroit tag team demolition awesome int...          117   \n",
       "972   businesses e deluged invoices make standwout c...          132   \n",
       "634                     @5sosfamupdater social casualty           31   \n",
       "131         @tmfkco sounds like terrible time ill right           58   \n",
       "2658  55432 1950 lionel trains smoke locomotives mag...          123   \n",
       "\n",
       "      word_count  hashtag_count  mention_count  has_url  sentiment_score  \\\n",
       "1032          17              0              1        0         0.250000   \n",
       "972           25              0              0        0         0.250000   \n",
       "634            3              0              1        0         0.033333   \n",
       "131           10              0              1        0        -0.357143   \n",
       "2658          11              0              0        1         0.000000   \n",
       "\n",
       "      noun_count  verb_count  adverb_count  adjective_count  profanity_count  \n",
       "1032           8           2             2                1                0  \n",
       "972            8           3             0                1                0  \n",
       "634            1           1             0                1                0  \n",
       "131            2           1             2                1                0  \n",
       "2658           7           1             0                1                0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization\n",
    "- Convert the cleaned text data into numerical features using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=10000)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf.fit_transform(train_df['clean_text'])\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = tfidf.transform(test_df['clean_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Embeddings\n",
    "- Generate BERT embeddings for the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't load tokenizer for 'bert-base-uncased'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'bert-base-uncased' is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#load tokenizer and BERT model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mBertTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbert-base-uncased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m BertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-based-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#tokenize and encode the text\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Tokenize and encode the text\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2275\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2272\u001b[0m \u001b[38;5;66;03m# If one passes a GGUF file path to `gguf_file` there is no need for this check as the tokenizer will be\u001b[39;00m\n\u001b[0;32m   2273\u001b[0m \u001b[38;5;66;03m# loaded directly from the GGUF file.\u001b[39;00m\n\u001b[0;32m   2274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(full_file_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m full_file_name \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m gguf_file:\n\u001b[1;32m-> 2275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m   2276\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load tokenizer for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2277\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2278\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining all relevant files for a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2280\u001b[0m     )\n\u001b[0;32m   2282\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_id, file_path \u001b[38;5;129;01min\u001b[39;00m vocab_files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   2283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resolved_vocab_files:\n",
      "\u001b[1;31mOSError\u001b[0m: Can't load tokenizer for 'bert-base-uncased'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'bert-base-uncased' is the correct path to a directory containing all relevant files for a BertTokenizer tokenizer."
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "#load tokenizer and BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-based-uncased')\n",
    "\n",
    "#tokenize and encode the text\n",
    "# Tokenize and encode the text\n",
    "def get_bert_embeddings(text_list):\n",
    "   inputs = tokenizer(text_list, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "   with torch.no_grad():\n",
    "      outputs = bert_model(**inputs)\n",
    "   return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "# Get BERT embeddings for train and test data\n",
    "X_train_bert = get_bert_embeddings(train_df['clean_text'].tolist())\n",
    "X_test_bert = get_bert_embeddings(test_df['clean_text'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = np.hstack((X_train_tfidf.toarray(), X_train_bert, \n",
    "                              train_df[['text_length', 'word_count', 'hashtag_count', 'mention_count', 'has_url', \n",
    "                                       'sentiment_score', 'noun_count', 'verb_count', 'adverb_count', 'adjective_count', 'profanity_count']].values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
